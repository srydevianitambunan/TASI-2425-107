{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   reviewerID        asin                                       title  \\\n",
      "0      366595  MNTGGZBSGA  Heavenly Highway Hymns: Shaped-Note Hymnal   \n",
      "1      591833  MNTGGZBSGA  Heavenly Highway Hymns: Shaped-Note Hymnal   \n",
      "2      222211  MNTGGZBSGA  Heavenly Highway Hymns: Shaped-Note Hymnal   \n",
      "3      351171  MNTGGZBSGA  Heavenly Highway Hymns: Shaped-Note Hymnal   \n",
      "4      284978  MNTGGZBSGA  Heavenly Highway Hymns: Shaped-Note Hymnal   \n",
      "\n",
      "   rating_float  \n",
      "0             1  \n",
      "1             1  \n",
      "2             1  \n",
      "3             1  \n",
      "4             1  \n"
     ]
    }
   ],
   "source": [
    "# Membaca file CSV hasil merge\n",
    "df_books = pd.read_csv('Amazon_Books(inter).csv')\n",
    "\n",
    "# Menampilkan 5 baris teratas\n",
    "print(df_books.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data berhasil disimpan ke Dataset_Books(inter).csv\n",
      "   reviewerID:token  asin:token                                 title:token  \\\n",
      "0            366595  MNTGGZBSGA  Heavenly Highway Hymns: Shaped-Note Hymnal   \n",
      "1            591833  MNTGGZBSGA  Heavenly Highway Hymns: Shaped-Note Hymnal   \n",
      "2            222211  MNTGGZBSGA  Heavenly Highway Hymns: Shaped-Note Hymnal   \n",
      "3            351171  MNTGGZBSGA  Heavenly Highway Hymns: Shaped-Note Hymnal   \n",
      "4            284978  MNTGGZBSGA  Heavenly Highway Hymns: Shaped-Note Hymnal   \n",
      "\n",
      "   rating_float:token  \n",
      "0                   1  \n",
      "1                   1  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   1  \n"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "new_columns = {col: f\"{col}:token\" for col in df_books.columns}\n",
    "df_books.rename(columns=new_columns, inplace=True)\n",
    "\n",
    "# Simpan ke file CSV baru\n",
    "df_books.to_csv(\"Dataset_Books(inter).csv\", index=False)\n",
    "\n",
    "# Print hasil\n",
    "print(\"Data berhasil disimpan ke Dataset_Books(inter).csv\")\n",
    "print(df_books.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "✅ Data successfully saved to Amazon_Books(new).inter\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define input and output files \n",
    "input_file2 = \"Dataset_Books(inter).csv\"\n",
    "inter_file = \"Amazon_Books(new).inter\"\n",
    "\n",
    "# Read in chunks to handle large files\n",
    "chunk_size = 100000  \n",
    "\n",
    "# Create empty file with headers\n",
    "pd.DataFrame(columns=[\"user_id:token\", \"item_id:token\", \"rating:float\"]).to_csv(inter_file, index=False, sep=\"\\t\")\n",
    "\n",
    "# Process file in chunks\n",
    "for chunk in pd.read_csv(input_file2, chunksize=chunk_size, low_memory=False):\n",
    "    # Debugging: Print columns to check names\n",
    "    print(\"Columns in chunk before renaming:\", chunk.columns.tolist())\n",
    "    \n",
    "    # Ensure correct column names\n",
    "    expected_columns = {\"reviewerID:token\": \"user_id:token\", \"asin:token\": \"item_id:token\", \"rating_float:token\": \"rating:float\"}\n",
    "    \n",
    "    # Rename columns only if they exist in the chunk\n",
    "    available_cols = {col: new_col for col, new_col in expected_columns.items() if col in chunk.columns}\n",
    "    chunk.rename(columns=available_cols, inplace=True)\n",
    "    \n",
    "    # Debugging: Print columns after renaming\n",
    "    print(\"Columns in chunk after renaming:\", chunk.columns.tolist())\n",
    "    \n",
    "    # Ensure all required columns exist\n",
    "    for new_col in expected_columns.values():\n",
    "        if new_col not in chunk.columns:\n",
    "            print(f\"⚠️ Warning: Column '{new_col}' is missing, filling with default values.\")\n",
    "            chunk[new_col] = 1 if new_col == \"rating:float\" else \"unknown\"\n",
    "    \n",
    "    # Select only the required columns\n",
    "    inter_data = chunk[[\"user_id:token\", \"item_id:token\", \"rating:float\"]]\n",
    "    \n",
    "    # Append data to respective files (tab-separated)\n",
    "    inter_data.to_csv(inter_file, mode=\"a\", header=False, index=False, sep=\"\\t\")\n",
    "\n",
    "print(\"✅ Data successfully saved to Amazon_Books(new).inter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>586297</td>\n",
       "      <td>GAYDAMJVGI</td>\n",
       "      <td>Steve Green: Hide 'em in Your Heart: 13 Bible ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>226404</td>\n",
       "      <td>GAYDAMJVGI</td>\n",
       "      <td>Steve Green: Hide 'em in Your Heart: 13 Bible ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178001</td>\n",
       "      <td>GAYDAMJVGI</td>\n",
       "      <td>Steve Green: Hide 'em in Your Heart: 13 Bible ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>388575</td>\n",
       "      <td>GAYDAMJVGI</td>\n",
       "      <td>Steve Green: Hide 'em in Your Heart: 13 Bible ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>515515</td>\n",
       "      <td>GAYDAMJVGI</td>\n",
       "      <td>Steve Green: Hide 'em in Your Heart: 13 Bible ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewerID        asin                                              title\n",
       "0      586297  GAYDAMJVGI  Steve Green: Hide 'em in Your Heart: 13 Bible ...\n",
       "1      226404  GAYDAMJVGI  Steve Green: Hide 'em in Your Heart: 13 Bible ...\n",
       "2      178001  GAYDAMJVGI  Steve Green: Hide 'em in Your Heart: 13 Bible ...\n",
       "3      388575  GAYDAMJVGI  Steve Green: Hide 'em in Your Heart: 13 Bible ...\n",
       "4      515515  GAYDAMJVGI  Steve Green: Hide 'em in Your Heart: 13 Bible ..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies = pd.read_csv('Attributes_Movies_and_TV.csv')\n",
    "\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data berhasil disimpan ke Amazon_Movies&TV(inter).csv\n"
     ]
    }
   ],
   "source": [
    "# Tambah kolom rating:float dengan nilai 1 untuk semua baris\n",
    "df_movies[\"rating:float\"] = 1\n",
    "\n",
    "# Simpan ke file CSV baru\n",
    "df_movies.to_csv(\"Amazon_Movies&TV(inter).csv\", index=False)\n",
    "\n",
    "# Print hasil\n",
    "print(\"Data berhasil disimpan ke Amazon_Movies&TV(inter).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   reviewerID        asin                                              title  \\\n",
      "0      586297  GAYDAMJVGI  Steve Green: Hide 'em in Your Heart: 13 Bible ...   \n",
      "1      226404  GAYDAMJVGI  Steve Green: Hide 'em in Your Heart: 13 Bible ...   \n",
      "2      178001  GAYDAMJVGI  Steve Green: Hide 'em in Your Heart: 13 Bible ...   \n",
      "3      388575  GAYDAMJVGI  Steve Green: Hide 'em in Your Heart: 13 Bible ...   \n",
      "4      515515  GAYDAMJVGI  Steve Green: Hide 'em in Your Heart: 13 Bible ...   \n",
      "\n",
      "   rating_float  \n",
      "0             1  \n",
      "1             1  \n",
      "2             1  \n",
      "3             1  \n",
      "4             1  \n"
     ]
    }
   ],
   "source": [
    "# Membaca file CSV hasil merge\n",
    "df2 = pd.read_csv('Amazon_Movies&TV(inter).csv')\n",
    "\n",
    "# Menampilkan 5 baris teratas\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data berhasil disimpan ke Amazon_Movies&TV(inter)).csv\n",
      "   reviewerID:token  asin:token  \\\n",
      "0            586297  GAYDAMJVGI   \n",
      "1            226404  GAYDAMJVGI   \n",
      "2            178001  GAYDAMJVGI   \n",
      "3            388575  GAYDAMJVGI   \n",
      "4            515515  GAYDAMJVGI   \n",
      "\n",
      "                                         title:token  rating_float:token  \n",
      "0  Steve Green: Hide 'em in Your Heart: 13 Bible ...                   1  \n",
      "1  Steve Green: Hide 'em in Your Heart: 13 Bible ...                   1  \n",
      "2  Steve Green: Hide 'em in Your Heart: 13 Bible ...                   1  \n",
      "3  Steve Green: Hide 'em in Your Heart: 13 Bible ...                   1  \n",
      "4  Steve Green: Hide 'em in Your Heart: 13 Bible ...                   1  \n"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "new_columns = {col: f\"{col}:token\" for col in df_movies.columns}\n",
    "df_movies.rename(columns=new_columns, inplace=True)\n",
    "\n",
    "# Simpan ke file CSV baru\n",
    "df_movies.to_csv(\"Amazon_Movies&TV(inter).csv\", index=False)\n",
    "\n",
    "# Print hasil\n",
    "print(\"Data berhasil disimpan ke Amazon_Movies&TV(inter)).csv\")\n",
    "print(df_movies.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "Columns in chunk before renaming: ['reviewerID:token', 'asin:token', 'title:token', 'rating_float:token']\n",
      "Columns in chunk after renaming: ['user_id:token', 'item_id:token', 'title:token', 'rating:float']\n",
      "✅ Data successfully saved to Amazon_Movies&TV.inter\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define input and output files \n",
    "input_file2 = \"Amazon_Movies&TV(inter).csv\"\n",
    "inter_file = \"Amazon_Movies&TV.inter\"\n",
    "\n",
    "# Read in chunks to handle large files\n",
    "chunk_size = 100000  \n",
    "\n",
    "# Create empty file with headers\n",
    "pd.DataFrame(columns=[\"user_id:token\", \"item_id:token\", \"rating:float\"]).to_csv(inter_file, index=False, sep=\"\\t\")\n",
    "\n",
    "# Process file in chunks\n",
    "for chunk in pd.read_csv(input_file2, chunksize=chunk_size, low_memory=False):\n",
    "    # Debugging: Print columns to check names\n",
    "    print(\"Columns in chunk before renaming:\", chunk.columns.tolist())\n",
    "    \n",
    "    # Ensure correct column names\n",
    "    expected_columns = {\"reviewerID:token\": \"user_id:token\", \"asin:token\": \"item_id:token\", \"rating_float:token\": \"rating:float\"}\n",
    "    \n",
    "    # Rename columns only if they exist in the chunk\n",
    "    available_cols = {col: new_col for col, new_col in expected_columns.items() if col in chunk.columns}\n",
    "    chunk.rename(columns=available_cols, inplace=True)\n",
    "    \n",
    "    # Debugging: Print columns after renaming\n",
    "    print(\"Columns in chunk after renaming:\", chunk.columns.tolist())\n",
    "    \n",
    "    # Ensure all required columns exist\n",
    "    for new_col in expected_columns.values():\n",
    "        if new_col not in chunk.columns:\n",
    "            print(f\"⚠️ Warning: Column '{new_col}' is missing, filling with default values.\")\n",
    "            chunk[new_col] = 1 if new_col == \"rating:float\" else \"unknown\"\n",
    "    \n",
    "    # Select only the required columns\n",
    "    inter_data = chunk[[\"user_id:token\", \"item_id:token\", \"rating:float\"]]\n",
    "    \n",
    "    # Append data to respective files (tab-separated)\n",
    "    inter_data.to_csv(inter_file, mode=\"a\", header=False, index=False, sep=\"\\t\")\n",
    "\n",
    "print(\"✅ Data successfully saved to Amazon_Movies&TV.inter\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
